{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\valde\\Documents\\IF\\Minicurso Keras\\env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A importação das funções que serão utlizadas em bibiolitecas que são muito grandes é uma boa pratica, caso fosse feita a importação completa do Keras ou do Sklearn levaria muito tempo e tornaria a escrita do codigo mais complexa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2095.610107</td>\n",
       "      <td>2081.389893</td>\n",
       "      <td>2089.409912</td>\n",
       "      <td>2086.590088</td>\n",
       "      <td>3.587980e+09</td>\n",
       "      <td>2086.590088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2094.120117</td>\n",
       "      <td>2070.290039</td>\n",
       "      <td>2084.419922</td>\n",
       "      <td>2089.139893</td>\n",
       "      <td>3.884930e+09</td>\n",
       "      <td>2089.139893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2093.000000</td>\n",
       "      <td>2086.300049</td>\n",
       "      <td>2089.300049</td>\n",
       "      <td>2088.870117</td>\n",
       "      <td>2.852940e+09</td>\n",
       "      <td>2088.870117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2093.000000</td>\n",
       "      <td>2086.300049</td>\n",
       "      <td>2089.300049</td>\n",
       "      <td>2088.870117</td>\n",
       "      <td>2.852940e+09</td>\n",
       "      <td>2088.870117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2093.290039</td>\n",
       "      <td>2084.129883</td>\n",
       "      <td>2088.820068</td>\n",
       "      <td>2090.110107</td>\n",
       "      <td>1.466840e+09</td>\n",
       "      <td>2090.110107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>3628.510010</td>\n",
       "      <td>3600.159912</td>\n",
       "      <td>3600.159912</td>\n",
       "      <td>3626.909912</td>\n",
       "      <td>5.281980e+09</td>\n",
       "      <td>3626.909912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>3623.110107</td>\n",
       "      <td>3588.679932</td>\n",
       "      <td>3610.310059</td>\n",
       "      <td>3609.530029</td>\n",
       "      <td>4.799570e+09</td>\n",
       "      <td>3609.530029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>3619.090088</td>\n",
       "      <td>3567.330078</td>\n",
       "      <td>3612.090088</td>\n",
       "      <td>3567.790039</td>\n",
       "      <td>5.274450e+09</td>\n",
       "      <td>3567.790039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1823</th>\n",
       "      <td>3585.219971</td>\n",
       "      <td>3543.840088</td>\n",
       "      <td>3559.409912</td>\n",
       "      <td>3581.870117</td>\n",
       "      <td>4.347200e+09</td>\n",
       "      <td>3581.870117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>3581.229980</td>\n",
       "      <td>3556.850098</td>\n",
       "      <td>3579.310059</td>\n",
       "      <td>3557.540039</td>\n",
       "      <td>2.236662e+09</td>\n",
       "      <td>3557.540039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1825 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             High          Low         Open        Close        Volume  \\\n",
       "0     2095.610107  2081.389893  2089.409912  2086.590088  3.587980e+09   \n",
       "1     2094.120117  2070.290039  2084.419922  2089.139893  3.884930e+09   \n",
       "2     2093.000000  2086.300049  2089.300049  2088.870117  2.852940e+09   \n",
       "3     2093.000000  2086.300049  2089.300049  2088.870117  2.852940e+09   \n",
       "4     2093.290039  2084.129883  2088.820068  2090.110107  1.466840e+09   \n",
       "...           ...          ...          ...          ...           ...   \n",
       "1820  3628.510010  3600.159912  3600.159912  3626.909912  5.281980e+09   \n",
       "1821  3623.110107  3588.679932  3610.310059  3609.530029  4.799570e+09   \n",
       "1822  3619.090088  3567.330078  3612.090088  3567.790039  5.274450e+09   \n",
       "1823  3585.219971  3543.840088  3559.409912  3581.870117  4.347200e+09   \n",
       "1824  3581.229980  3556.850098  3579.310059  3557.540039  2.236662e+09   \n",
       "\n",
       "        Adj Close  \n",
       "0     2086.590088  \n",
       "1     2089.139893  \n",
       "2     2088.870117  \n",
       "3     2088.870117  \n",
       "4     2090.110107  \n",
       "...           ...  \n",
       "1820  3626.909912  \n",
       "1821  3609.530029  \n",
       "1822  3567.790039  \n",
       "1823  3581.870117  \n",
       "1824  3557.540039  \n",
       "\n",
       "[1825 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'yahoo_stock.csv')\n",
    "df.drop(columns=['Date'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho = int(len(df) * 0.2)\n",
    "teste = df.iloc[:tamanho]\n",
    "treino = df.iloc[tamanho:]\n",
    "\n",
    "target = ['High']\n",
    "\n",
    "df_teste = teste\n",
    "preditor_teste = list(set(list(df_teste.columns)) - set(target))\n",
    "X_teste = df_teste[preditor_teste].values\n",
    "y_teste = df_teste[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = treino\n",
    "preditor_treino = list(set(list(df_treino.columns)) - set(target))\n",
    "X_treino = df_treino[preditor_treino].values\n",
    "y_treino = df_treino[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na sequencia acima é feito o tratamentos dos dados, separando o que seria o nosso alvo e o qual será nossa entrada dos dados na rede, como são mulplas entradas é importante lembrar que a primeira camada de uma rede neural deve ser no minimo o numero de colunas dos dados de entrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\valde\\Documents\\IF\\Minicurso Keras\\env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\valde\\Documents\\IF\\Minicurso Keras\\env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, activation='linear'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='huber')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possivel adicionar diversas camadas a rede não apenas se limitando a duas camadas ou apenas uma, vale lembrar que a saida da rede é o numero de neuronios da ultima camada. \n",
    "\n",
    "Funções de ativação que podem ser testadas, lembrando que existem muitas outras:\n",
    "    linear\n",
    "    relu\n",
    "    selu\n",
    "    leaky_relu\n",
    "    sigmoid\n",
    "    elu\n",
    "    tanh \n",
    "\n",
    "Funções de perda que podem ser testadas, lembrando que existem muitas outras e você pode criar as suas propias:\n",
    "    huber\n",
    "    'mean_squared_error'\n",
    "    'binary_crossentropy'\n",
    "    'mean_absolute_error'\n",
    "    'huber_loss'\n",
    "    'logcosh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x195470b2990>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_treino, y_treino, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 637us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ -6332888.],\n",
       "       [ -6856868.],\n",
       "       [ -5035884.],\n",
       "       [ -5035884.],\n",
       "       [ -2589822.],\n",
       "       [ -2589822.],\n",
       "       [ -2589822.],\n",
       "       [ -7545440.],\n",
       "       [ -6552044.],\n",
       "       [ -6973012.],\n",
       "       [ -7600888.],\n",
       "       [ -7439368.],\n",
       "       [ -7439368.],\n",
       "       [ -7439368.],\n",
       "       [ -7137344.],\n",
       "       [ -7366472.],\n",
       "       [ -7739840.],\n",
       "       [ -6557404.],\n",
       "       [ -7591192.],\n",
       "       [ -7591192.],\n",
       "       [ -7591192.],\n",
       "       [ -8140736.],\n",
       "       [ -7683816.],\n",
       "       [ -8181560.],\n",
       "       [ -7637840.],\n",
       "       [-11794792.],\n",
       "       [-11794792.],\n",
       "       [-11794792.],\n",
       "       [ -6636920.],\n",
       "       [ -6214408.],\n",
       "       [ -6149692.],\n",
       "       [ -2492788.],\n",
       "       [ -2492758.],\n",
       "       [ -2492758.],\n",
       "       [ -2492758.],\n",
       "       [ -4399836.],\n",
       "       [ -4487208.],\n",
       "       [ -4179116.],\n",
       "       [ -4687040.],\n",
       "       [ -4687040.],\n",
       "       [ -4687040.],\n",
       "       [ -4687040.],\n",
       "       [ -7598120.],\n",
       "       [ -6542172.],\n",
       "       [ -7653904.],\n",
       "       [ -8959904.],\n",
       "       [ -8233232.],\n",
       "       [ -8233232.],\n",
       "       [ -8233232.],\n",
       "       [ -8131496.],\n",
       "       [ -8625712.],\n",
       "       [ -8978136.],\n",
       "       [ -9250016.],\n",
       "       [ -9651240.],\n",
       "       [ -9651240.],\n",
       "       [ -9651240.],\n",
       "       [ -9651240.],\n",
       "       [ -8698096.],\n",
       "       [-11323320.],\n",
       "       [ -8963832.],\n",
       "       [ -8651128.],\n",
       "       [ -8651128.],\n",
       "       [ -8651384.],\n",
       "       [ -7768192.],\n",
       "       [ -7691608.],\n",
       "       [ -8390464.],\n",
       "       [ -8283008.],\n",
       "       [ -9702784.],\n",
       "       [ -9702784.],\n",
       "       [ -9702784.],\n",
       "       [ -7629048.],\n",
       "       [ -7877264.],\n",
       "       [ -9129752.],\n",
       "       [ -9165720.],\n",
       "       [ -8701024.],\n",
       "       [ -8701024.],\n",
       "       [ -8701024.],\n",
       "       [ -9947664.],\n",
       "       [ -9147960.],\n",
       "       [ -7891264.],\n",
       "       [ -9708112.],\n",
       "       [ -8290056.],\n",
       "       [ -8290056.],\n",
       "       [ -8290056.],\n",
       "       [ -8290056.],\n",
       "       [ -8066936.],\n",
       "       [ -8845080.],\n",
       "       [ -7830168.],\n",
       "       [ -7312112.],\n",
       "       [ -7312112.],\n",
       "       [ -7312112.],\n",
       "       [ -7156480.],\n",
       "       [ -6866992.],\n",
       "       [ -7619992.],\n",
       "       [ -7268872.],\n",
       "       [ -7675000.],\n",
       "       [ -7674992.],\n",
       "       [ -7674992.],\n",
       "       [ -8097824.],\n",
       "       [ -8506712.],\n",
       "       [ -8236432.],\n",
       "       [ -8968848.],\n",
       "       [-10677360.],\n",
       "       [-10677360.],\n",
       "       [-10677360.],\n",
       "       [ -8768336.],\n",
       "       [ -8192248.],\n",
       "       [ -7127192.],\n",
       "       [ -7724944.],\n",
       "       [ -7198752.],\n",
       "       [ -7198752.],\n",
       "       [ -7198752.],\n",
       "       [ -6156260.],\n",
       "       [ -6283988.],\n",
       "       [ -7160608.],\n",
       "       [ -7996208.],\n",
       "       [-11477576.],\n",
       "       [-11477576.],\n",
       "       [-11477576.],\n",
       "       [ -5959852.],\n",
       "       [ -6033796.],\n",
       "       [ -6423884.],\n",
       "       [ -6014732.],\n",
       "       [ -6014732.],\n",
       "       [ -6014732.],\n",
       "       [ -6014732.],\n",
       "       [ -4958456.],\n",
       "       [ -6746508.],\n",
       "       [ -6337028.],\n",
       "       [ -6557704.],\n",
       "       [ -6618912.],\n",
       "       [ -6618912.],\n",
       "       [ -6618912.],\n",
       "       [ -6152592.],\n",
       "       [ -7333656.],\n",
       "       [ -6620328.],\n",
       "       [ -6709180.],\n",
       "       [ -5929636.],\n",
       "       [ -5929636.],\n",
       "       [ -5929636.],\n",
       "       [ -6297384.],\n",
       "       [ -7483112.],\n",
       "       [ -7398600.],\n",
       "       [ -6647008.],\n",
       "       [ -6533156.],\n",
       "       [ -6533156.],\n",
       "       [ -6533156.],\n",
       "       [ -5854628.],\n",
       "       [ -6877976.],\n",
       "       [ -7386432.],\n",
       "       [ -7369424.],\n",
       "       [ -6690532.],\n",
       "       [ -6690532.],\n",
       "       [ -6690532.],\n",
       "       [ -5859756.],\n",
       "       [ -6278700.],\n",
       "       [ -7236792.],\n",
       "       [ -7606800.],\n",
       "       [ -8303840.],\n",
       "       [ -8303840.],\n",
       "       [ -8303840.],\n",
       "       [ -6779608.],\n",
       "       [ -7366000.],\n",
       "       [ -7163432.],\n",
       "       [ -7075064.],\n",
       "       [ -6700708.],\n",
       "       [ -6700708.],\n",
       "       [ -6700708.],\n",
       "       [ -6687056.],\n",
       "       [ -6354552.],\n",
       "       [ -6745936.],\n",
       "       [ -6675968.],\n",
       "       [ -6318692.],\n",
       "       [ -6318692.],\n",
       "       [ -6318692.],\n",
       "       [ -6180244.],\n",
       "       [ -7252240.],\n",
       "       [ -7238824.],\n",
       "       [ -6789584.],\n",
       "       [ -6191152.],\n",
       "       [ -6191152.],\n",
       "       [ -6191152.],\n",
       "       [ -5393180.],\n",
       "       [ -6402572.],\n",
       "       [ -6811556.],\n",
       "       [ -5703136.],\n",
       "       [ -5435044.],\n",
       "       [ -5435044.],\n",
       "       [ -5435044.],\n",
       "       [ -5435044.],\n",
       "       [ -7967832.],\n",
       "       [ -6222176.],\n",
       "       [ -6411940.],\n",
       "       [ -6403272.],\n",
       "       [ -6403272.],\n",
       "       [ -6403272.],\n",
       "       [ -6075424.],\n",
       "       [ -6238960.],\n",
       "       [ -6287300.],\n",
       "       [ -5807676.],\n",
       "       [ -6204168.],\n",
       "       [ -6204168.],\n",
       "       [ -6204168.],\n",
       "       [ -5987228.],\n",
       "       [ -6636212.],\n",
       "       [ -6256636.],\n",
       "       [ -6404060.],\n",
       "       [ -8741264.],\n",
       "       [ -8741264.],\n",
       "       [ -8741264.],\n",
       "       [ -6120212.],\n",
       "       [ -5706524.],\n",
       "       [ -5592092.],\n",
       "       [ -5821104.],\n",
       "       [-13408344.],\n",
       "       [-13408344.],\n",
       "       [-13408344.],\n",
       "       [ -9585656.],\n",
       "       [ -7740872.],\n",
       "       [ -7486688.],\n",
       "       [ -8159168.],\n",
       "       [ -6105252.],\n",
       "       [ -6105316.],\n",
       "       [ -6105316.],\n",
       "       [ -6105252.],\n",
       "       [ -6457208.],\n",
       "       [ -6900088.],\n",
       "       [ -6362112.],\n",
       "       [ -6367488.],\n",
       "       [ -6367488.],\n",
       "       [ -6367488.],\n",
       "       [ -5742448.],\n",
       "       [ -7232656.],\n",
       "       [ -6181856.],\n",
       "       [ -6117096.],\n",
       "       [ -5511744.],\n",
       "       [ -5511744.],\n",
       "       [ -5511744.],\n",
       "       [ -5311932.],\n",
       "       [ -5239580.],\n",
       "       [ -5669316.],\n",
       "       [ -6069988.],\n",
       "       [ -5336444.],\n",
       "       [ -5336444.],\n",
       "       [ -5336444.],\n",
       "       [ -5396436.],\n",
       "       [ -6075960.],\n",
       "       [ -7052192.],\n",
       "       [ -6467636.],\n",
       "       [ -7128640.],\n",
       "       [ -7128640.],\n",
       "       [ -7128640.],\n",
       "       [ -6188364.],\n",
       "       [ -6793224.],\n",
       "       [ -6683312.],\n",
       "       [ -6547024.],\n",
       "       [ -6465544.],\n",
       "       [ -6465544.],\n",
       "       [ -6465544.],\n",
       "       [ -5873468.],\n",
       "       [ -5885288.],\n",
       "       [ -5745372.],\n",
       "       [ -6042132.],\n",
       "       [ -5296692.],\n",
       "       [ -5296692.],\n",
       "       [ -5296692.],\n",
       "       [ -5434008.],\n",
       "       [ -5642084.],\n",
       "       [ -5981736.],\n",
       "       [ -5825804.],\n",
       "       [ -5444984.],\n",
       "       [ -5444984.],\n",
       "       [ -5444984.],\n",
       "       [ -4902868.],\n",
       "       [ -5368612.],\n",
       "       [ -5557000.],\n",
       "       [ -5241348.],\n",
       "       [ -5899500.],\n",
       "       [ -5899500.],\n",
       "       [ -5899500.],\n",
       "       [ -4686240.],\n",
       "       [ -5307400.],\n",
       "       [ -6647844.],\n",
       "       [ -5987404.],\n",
       "       [ -5456184.],\n",
       "       [ -5456184.],\n",
       "       [ -5456184.],\n",
       "       [ -5456184.],\n",
       "       [ -6085424.],\n",
       "       [ -5859096.],\n",
       "       [ -6579788.],\n",
       "       [ -7472856.],\n",
       "       [ -7472856.],\n",
       "       [ -7472856.],\n",
       "       [ -7078528.],\n",
       "       [ -7310128.],\n",
       "       [ -6467328.],\n",
       "       [ -5955004.],\n",
       "       [ -8850000.],\n",
       "       [ -8850000.],\n",
       "       [ -8850000.],\n",
       "       [ -5583060.],\n",
       "       [ -5543560.],\n",
       "       [ -6551892.],\n",
       "       [ -6270988.],\n",
       "       [ -5855232.],\n",
       "       [ -5855232.],\n",
       "       [ -5855232.],\n",
       "       [ -5676896.],\n",
       "       [ -6067944.],\n",
       "       [ -6868616.],\n",
       "       [ -7499936.],\n",
       "       [ -7366152.],\n",
       "       [ -7366152.],\n",
       "       [ -7366152.],\n",
       "       [ -5538044.],\n",
       "       [ -6620568.],\n",
       "       [ -6895244.],\n",
       "       [ -6109916.],\n",
       "       [ -6389384.],\n",
       "       [ -6389380.],\n",
       "       [ -6389380.],\n",
       "       [ -5148224.],\n",
       "       [ -6068860.],\n",
       "       [ -5254972.],\n",
       "       [ -6319696.],\n",
       "       [ -5698036.],\n",
       "       [ -5698036.],\n",
       "       [ -5698036.],\n",
       "       [ -4996072.],\n",
       "       [ -5595340.],\n",
       "       [ -5935384.],\n",
       "       [ -5890512.],\n",
       "       [ -6087508.],\n",
       "       [ -6087508.],\n",
       "       [ -6087508.],\n",
       "       [ -5925900.],\n",
       "       [ -6621280.],\n",
       "       [ -6663340.],\n",
       "       [ -7421504.],\n",
       "       [ -7094496.],\n",
       "       [ -7094496.],\n",
       "       [ -7094496.],\n",
       "       [ -6923200.],\n",
       "       [ -7999096.],\n",
       "       [ -7498592.],\n",
       "       [ -6860336.],\n",
       "       [ -6774028.],\n",
       "       [ -6774028.],\n",
       "       [ -6774028.],\n",
       "       [ -6594448.],\n",
       "       [ -6913476.],\n",
       "       [-11056024.],\n",
       "       [-11386800.],\n",
       "       [ -8803864.],\n",
       "       [ -8803864.],\n",
       "       [ -8803864.],\n",
       "       [ -9472880.],\n",
       "       [ -8019920.],\n",
       "       [ -6761320.],\n",
       "       [ -6723340.],\n",
       "       [ -6305600.],\n",
       "       [ -6305600.],\n",
       "       [ -6305600.],\n",
       "       [ -6366628.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_teste)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6966013346.422425"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2 = r2_score(y_teste, pred)\n",
    "\n",
    "r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
